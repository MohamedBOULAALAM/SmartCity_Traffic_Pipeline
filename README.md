# ðŸš¦ SmartCity Traffic Analytics Pipeline

<div align="center">

![Pipeline Status](https://img.shields.io/badge/Pipeline-Operational-success?style=for-the-badge)
![Docker](https://img.shields.io/badge/Docker-Compose-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-231F20?style=for-the-badge&logo=apache-kafka&logoColor=white)
![Apache Spark](https://img.shields.io/badge/Apache%20Spark-E25A1C?style=for-the-badge&logo=apache-spark&logoColor=white)
![Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=for-the-badge&logo=apache-airflow&logoColor=white)

**Pipeline Big Data End-to-End pour l'analyse du trafic urbain en temps rÃ©el**

[Architecture](#-architecture) â€¢
[Installation](#-installation-rapide) â€¢
[Documentation](#-documentation) â€¢
[Captures](#-captures-dÃ©cran)

</div>

---

## ðŸ“‹ Table des MatiÃ¨res

- [ðŸŽ¯ PrÃ©sentation](#-prÃ©sentation)
- [ðŸ—ï¸ Architecture](#ï¸-architecture)
- [ðŸ› ï¸ Stack Technique](#ï¸-stack-technique)
- [ðŸš€ Installation Rapide](#-installation-rapide)
- [ðŸ“Š Ã‰tapes du Pipeline](#-Ã©tapes-du-pipeline)
- [ðŸ“¸ Captures d&#39;Ã©cran](#-captures-dÃ©cran)
- [ðŸ“š Documentation](#-documentation)
- [ðŸ”§ Commandes Utiles](#-commandes-utiles)
- [ðŸŽ¯ Validation](#-validation)
- [ðŸ‘¤ Auteur](#-auteur)

---

## ðŸŽ¯ PrÃ©sentation

Ce projet implÃ©mente un **pipeline Big Data complet** pour analyser le trafic urbain en temps rÃ©el dans une Smart City. Le systÃ¨me ingÃ¨re, traite et visualise des donnÃ©es de capteurs de trafic pour fournir des insights sur la congestion, la vitesse moyenne et les patterns de circulation.

### FonctionnalitÃ©s Principales

âœ… **GÃ©nÃ©ration de donnÃ©es rÃ©alistes** avec patterns temporels et anomalies
âœ… **Ingestion temps rÃ©el** via Apache Kafka
âœ… **Stockage partitionnÃ©** dans HDFS (Data Lake)
âœ… **Traitement distribuÃ©** avec Apache Spark (KPIs)
âœ… **API REST** avec FastAPI pour exposer les mÃ©triques
âœ… **Dashboards interactifs** avec Grafana
âœ… **Orchestration automatique** avec Apache Airflow

---

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SMARTCITY TRAFFIC PIPELINE                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   GÃ©nÃ©rateur â”‚â”€â”€â”€â”€â”€>â”‚  Kafka   â”‚â”€â”€â”€â”€â”€>â”‚ Consumer â”‚â”€â”€â”€â”€â”€>â”‚   HDFS   â”‚
â”‚   DonnÃ©es    â”‚      â”‚  Topic   â”‚      â”‚  Python  â”‚      â”‚ (JSON L) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                  â”‚
                                                                  â–¼
                                                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                           â”‚  Spark   â”‚
                                                           â”‚  (KPIs)  â”‚
                                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                  â”‚
                                                                  â–¼
                                                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                           â”‚ Parquet  â”‚
                                                           â”‚Analytics â”‚
                                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                  â”‚
                                                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Airflow    â”‚â”€â”€â”€â”€â”€>â”‚ FastAPI  â”‚â”€â”€â”€â”€â”€>â”‚ Grafana  â”‚      â”‚  Users   â”‚
â”‚ Orchestrationâ”‚      â”‚   API    â”‚      â”‚Dashboard â”‚<â”€â”€â”€â”€â”€â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ› ï¸ Stack Technique

| Composant               | Version | Port       | RÃ´le                      |
| ----------------------- | ------- | ---------- | ------------------------- |
| **Apache Kafka**        | 7.5.0   | 9093       | Message Broker temps rÃ©el |
| **Apache Zookeeper**    | 7.5.0   | 2181       | Coordination Kafka        |
| **HDFS Namenode**       | 3.2.1   | 9870       | MÃ©tadonnÃ©es Data Lake     |
| **HDFS Datanode**       | 3.2.1   | -          | Stockage distribuÃ©        |
| **Apache Spark Master** | 3.5.1   | 8080, 7077 | Orchestration jobs        |
| **Apache Spark Worker** | 3.5.1   | 8081       | ExÃ©cution traitements     |
| **FastAPI**             | Latest  | 8000       | API REST Analytics        |
| **Grafana**             | Latest  | 3000       | Visualisation             |
| **Apache Airflow**      | 2.9.3   | 8085       | Orchestration DAGs        |
| **PostgreSQL**          | 13      | 5432       | MÃ©tadonnÃ©es Airflow       |

---

## ðŸš€ Installation Rapide

### PrÃ©requis

- **Docker Desktop** + Docker Compose
- **Python 3.8+** (pour le producteur Kafka)
- **8 GB RAM** minimum
- **20 GB** d'espace disque

### Ã‰tapes d'installation

```powershell
# 1. Cloner le repository
git clone https://github.com/MohamedBOULAALAM/SmartCity_Traffic_Pipeline.git
cd SmartCity_Traffic_Pipeline

# 2. Lancer la stack Docker (13 services)
docker compose up -d

# 3. Attendre que tous les services soient healthy (~60s)
docker compose ps

# 4. CrÃ©er le rÃ©pertoire HDFS
docker exec -it namenode hdfs dfs -mkdir -p /user/hdfs/traffic
docker exec -it namenode hdfs dfs -chown -R hdfs:hdfs /user/hdfs/traffic

# 5. Lancer le producteur Kafka
python scripts/kafka_producer.py

# 6. CrÃ©er l'utilisateur Airflow
docker exec airflow-webserver airflow users create \
    --username admin \
    --firstname Admin \
    --lastname User \
    --role Admin \
    --email admin@example.com \
    --password admin
```

### AccÃ¨s aux interfaces

| Service           | URL                   | Identifiants  |
| ----------------- | --------------------- | ------------- |
| **Grafana**       | http://localhost:3000 | admin / admin |
| **Airflow**       | http://localhost:8085 | admin / admin |
| **Spark Master**  | http://localhost:8080 | -             |
| **HDFS Namenode** | http://localhost:9870 | -             |
| **API Analytics** | http://localhost:8000 | -             |

---

## ðŸ“Š Ã‰tapes du Pipeline

### âœ… Ã‰tape 1 : GÃ©nÃ©ration de DonnÃ©es

**Fichier** : `scripts/traffic_data_generator.py`

GÃ©nÃ¨re des Ã©vÃ©nements JSON rÃ©alistes simulant 20 capteurs de trafic :

- 4 zones : Centre-Ville, PÃ©riphÃ©rie, Quartier-RÃ©sidentiel, Zone-Industrielle
- 4 types de routes : autoroute, avenue, rue, boulevard
- Patterns temporels : heures de pointe, normales, nuit
- Anomalies : accidents (5% probabilitÃ©)

**Format JSON** :

```json
{
  "sensor_id": 12,
  "timestamp": "2026-01-11T15:17:32+00:00",
  "zone": "Centre-Ville",
  "road_type": "avenue",
  "vehicle_count": 87,
  "average_speed": 42,
  "occupancy_rate": 58
}
```

![GÃ©nÃ©ration de donnÃ©es](captures/e2-2.png)

---

### âœ… Ã‰tape 2 : Ingestion Kafka

**Fichier** : `scripts/kafka_producer.py`

- Topic : `traffic-events`
- Garantie de livraison : `acks='all'`
- Intervalle : 2 secondes entre Ã©vÃ©nements

![Producteur Kafka](captures/e3-1.png)

---

### âœ… Ã‰tape 3 : Consommation Kafka

**Fichier** : `scripts/kafka_to_hdfs.py`

- Consumer Group : `hdfs-consumer-group`
- Service Docker `consumer` en continu
- Auto-offset : `earliest`

![Consumer Kafka](captures/e4-t0.png)

---

### âœ… Ã‰tape 4 : Stockage HDFS PartitionnÃ©

**CaractÃ©ristiques** :

- **Micro-batching** : 50 messages OU 30 secondes
- **Format** : JSON Lines (`.jsonl`)
- **Partitionnement dynamique** :

```
/user/hdfs/traffic/
  year=2026/
    month=01/
      day=11/
        zone=Centre-Ville/
          traffic_20260111151732.jsonl
        zone=PÃ©riphÃ©rie/
          traffic_20260111151755.jsonl
```

![HDFS PartitionnÃ©](captures/e4-t2.png)

---

### âœ… Ã‰tape 5 : Traitement Spark

**Fichier** : `scripts/spark_traffic_processing.py`

**Pipeline de traitement** :

1. Lecture JSON Lines depuis HDFS
2. Nettoyage et dÃ©duplication
3. UDF `congestion_level` (4 niveaux)
4. Calcul de 4 KPIs :
   - Vitesse moyenne par `road_type`
   - Occupation moyenne par `zone`
   - VÃ©hicules par heure
   - RÃ©partition congestion
5. Sauvegarde Parquet partitionnÃ©

![Job Spark](captures/e5-2.png)

![spark](captures/e5-3.png)

![captures/e5-3.png](spark)

**RÃ©sultats** :

![KPIs Parquet](captures/e5-6.png)

![cc](captures/e5-7c.png)

---

### âœ… Ã‰tape 6 : API REST & Visualisation

**Fichier** : `api/api_analytics.py`

**Endpoints** :

- `GET /traffic/zones` : Volume par zone
- `GET /traffic/congestion` : Top 5 zones congestionnÃ©es
- `GET /traffic/speed` : Vitesse par road_type
- `GET /traffic/trends` : VÃ©hicules par heure

![endpoint](captures/e6-1.png)

![endpoint](captures/e6-2.png)

**Dashboard Grafana** :

![Dashboard Grafana](captures/e6-dashbord.png)

**4 Panels** :

1. **Stat** : Trafic global (3062 Ã©vÃ©nements)
2. **Table** : Top zones congestionnÃ©es
3. **Bar Chart** : Vitesse par type de route
4. **Time Series** : VÃ©hicules par heure

---

### âœ… Ã‰tape 7 : Orchestration Airflow

**Fichier** : `dags/traffic_pipeline_dag.py`

**DAG Principal** : `traffic_pipeline` (@hourly)

**5 TÃ¢ches** :

1. `check_kafka_health` : VÃ©rification Kafka
2. `trigger_data_generation` : GÃ©nÃ©ration donnÃ©es
3. `spark_processing` : Job Spark
4. `validate_output` : Validation Parquet
5. `archive_raw_data` : Archivage

![Airflow DAG](captures/e7-3.png)

**Interface Airflow** :

![Airflow Interface](captures/e7-6.png)

---

## ðŸ“š Documentation

| Guide                                          | Description                        |
| ---------------------------------------------- | ---------------------------------- |
| [SPARK_SUBMIT_GUIDE.md](SPARK_SUBMIT_GUIDE.md) | Soumission jobs Spark              |
| [GRAFANA_GUIDE.md](GRAFANA_GUIDE.md)           | Configuration Grafana + Dashboards |
| [AIRFLOW_GUIDE.md](AIRFLOW_GUIDE.md)           | Orchestration Airflow + DAGs       |

---

## ðŸ”§ Commandes Utiles

### Docker

```powershell
# RedÃ©marrer la stack
docker compose down
docker compose up -d

# Voir les logs
docker logs -f consumer
docker logs -f api-analytics
docker logs -f spark-master

# VÃ©rifier l'Ã©tat
docker compose ps
```

### HDFS

```powershell
# Lister les fichiers
docker exec -it namenode hdfs dfs -ls /user/hdfs/traffic

# Lire un fichier
docker exec -it namenode hdfs dfs -cat /user/hdfs/traffic/year=2026/month=01/day=11/zone=Centre-Ville/traffic_*.jsonl | Select-Object -First 5

# Supprimer (reset)
docker exec -it namenode hdfs dfs -rm -r -skipTrash /user/hdfs/traffic
```

### Kafka

```powershell
# Lister les topics
docker exec -it kafka kafka-topics --bootstrap-server localhost:9093 --list

# Consommer manuellement
docker exec -it kafka kafka-console-consumer \
    --bootstrap-server localhost:9093 \
    --topic traffic-events \
    --from-beginning \
    --max-messages 5
```

### Spark

```powershell
# Soumettre un job
docker cp scripts/spark_traffic_processing.py spark-master:/tmp/
docker exec -it spark-master /opt/spark/bin/spark-submit \
    --master spark://spark-master:7077 \
    --deploy-mode client \
    --executor-memory 2g \
    --total-executor-cores 2 \
    /tmp/spark_traffic_processing.py
```

### API

```powershell
# Tester les endpoints
Invoke-WebRequest -Uri "http://localhost:8000/traffic/zones" -UseBasicParsing
Invoke-WebRequest -Uri "http://localhost:8000/traffic/congestion" -UseBasicParsing
Invoke-WebRequest -Uri "http://localhost:8000/traffic/speed" -UseBasicParsing
Invoke-WebRequest -Uri "http://localhost:8000/traffic/trends" -UseBasicParsing
```

### Airflow

```powershell
# Lister les DAGs
docker exec -it airflow-webserver airflow dags list

# Activer un DAG
docker exec airflow-webserver airflow dags unpause traffic_pipeline

# DÃ©clencher manuellement
docker exec -it airflow-webserver airflow dags trigger traffic_pipeline
```

---

## ðŸŽ¯ Validation

### Checklist ComplÃ¨te

- [X] **Ã‰tape 1** : GÃ©nÃ©ration de donnÃ©es rÃ©alistes
- [X] **Ã‰tape 2** : Ingestion Kafka fonctionnelle
- [X] **Ã‰tape 3** : Consumer Ã©crit dans HDFS
- [X] **Ã‰tape 4** : Partitionnement HDFS optimisÃ©
- [X] **Ã‰tape 5** : Job Spark calcule les KPIs
- [X] **Ã‰tape 6** : API expose les mÃ©triques
- [X] **Ã‰tape 6** : Dashboard Grafana opÃ©rationnel
- [X] **Ã‰tape 7** : DAG Airflow automatisÃ©

### Commandes de Validation

```powershell
# Ã‰tape 4 - HDFS
docker exec -it namenode hdfs dfs -ls /user/hdfs/traffic/year=2026/month=01/day=11

# Ã‰tape 5 - Spark
docker exec -it namenode hdfs dfs -ls /data/analytics/traffic/kpi_zone

# Ã‰tape 6 - API
Invoke-WebRequest -Uri "http://localhost:8000/traffic/zones" -UseBasicParsing

# Ã‰tape 7 - Airflow
docker exec -it airflow-webserver airflow dags list | Select-String "traffic"
```

---

## ðŸ› ï¸ ProblÃ¨mes RÃ©solus

| ProblÃ¨me                     | Cause                                             | Solution                               |
| ---------------------------- | ------------------------------------------------- | -------------------------------------- |
| **Permission denied HDFS**   | RÃ©pertoire appartient Ã  `root`                    | Utiliser `/user/hdfs/traffic`          |
| **socket.gaierror DataNode** | Consumer Windows ne rÃ©sout pas le hostname Docker | ExÃ©cuter consumer dans Docker          |
| **Connection refused Kafka** | Mauvaise configuration `advertised.listeners`     | Corriger dans `docker-compose.yml`     |
| **Consumer lit localhost**   | Consumer crÃ©Ã© au niveau module                    | DÃ©placer dans `main()`                 |
| **spark-submit introuvable** | Pas dans `$PATH`                                  | Utiliser `/opt/spark/bin/spark-submit` |
| **Erreur "seek" Parquet**    | Stream HDFS non-seekable                          | Charger en mÃ©moire avec `BytesIO`      |
| **Zone "Inconnu" dans API**  | Colonne dans partition, pas dans Parquet          | Extraire depuis chemin                 |

---

## ðŸ‘¤ Auteur

**Mohamed BOULAA LAM**

- ðŸ“§ Email : mohamedboulaalam01@gamil.com
- ðŸ”— GitHub : [@MohamedBOULAALAM](https://github.com/MohamedBOULAALAM)

---

Made with â¤ï¸ by Mohamed BOULAA LAM | Janvier 2026

</div>
