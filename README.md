# SmartCity Traffic Analytics â€“ Pipeline Big Data End-to-End

## ðŸŽ¯ Objectif du Projet

Pipeline Big Data complet pour analyser le trafic urbain en temps rÃ©el :

1. **GÃ©nÃ©ration** de donnÃ©es de trafic rÃ©alistes
2. **Ingestion** via Kafka
3. **Stockage** partitionnÃ© dans HDFS (Data Lake)
4. **Traitement** avec Spark (KPIs de congestion)
5. **API REST** avec FastAPI
6. **Visualisation** avec Grafana

**Ã‰tat actuel** : âœ… **Ã‰tapes 1-6 complÃ¨tes** (Pipeline opÃ©rationnel de bout en bout)

---

## ðŸ› ï¸ Stack Technique (Docker)

| Service           | Version | Port       | RÃ´le                      |
| ----------------- | ------- | ---------- | ------------------------- |
| **Kafka**         | 7.5.0   | 9093       | Broker de messages        |
| **Zookeeper**     | 7.5.0   | 2181       | Coordination Kafka        |
| **HDFS Namenode** | 3.2.1   | 9870       | MÃ©tadonnÃ©es HDFS          |
| **HDFS Datanode** | 3.2.1   | -          | Stockage blocs HDFS       |
| **Spark Master**  | 3.5.1   | 8080, 7077 | Orchestration traitements |
| **Spark Worker**  | 3.5.1   | 8081       | ExÃ©cution jobs Spark      |
| **API Analytics** | 3.10    | 8000       | API REST FastAPI          |
| **Grafana**       | latest  | 3000       | Visualisation dashboards  |
| **Airflow**       | 2.9.3   | 8085       | Orchestration DAGs        |
| **PostgreSQL**    | 13      | 5432       | MÃ©tadonnÃ©es Airflow       |

---

## ðŸ“‚ Architecture du Projet

```
SmartCity_Traffic_Pipeline/
â”œâ”€â”€ docker-compose.yml          # Stack complÃ¨te (13 services)
â”œâ”€â”€ .env                        # Variables d'environnement
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ traffic_data_generator.py   # GÃ©nÃ©ration d'Ã©vÃ©nements
â”‚   â”œâ”€â”€ kafka_producer.py           # Producteur Kafka
â”‚   â”œâ”€â”€ kafka_to_hdfs.py            # Consommateur â†’ HDFS
â”‚   â”œâ”€â”€ spark_traffic_processing.py # Traitement Spark (KPIs)
â”‚   â””â”€â”€ read_spark_results.py       # Lecture rÃ©sultats Parquet
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ api_analytics.py            # API FastAPI
â”‚   â””â”€â”€ requirements.txt            # DÃ©pendances API
â”œâ”€â”€ dags/                       # DAGs Airflow (Ã  venir)
â”œâ”€â”€ logs/                       # Logs Airflow
â”œâ”€â”€ captures/                   # Screenshots du pipeline
â”œâ”€â”€ GRAFANA_GUIDE.md            # Guide configuration Grafana
â”œâ”€â”€ SPARK_SUBMIT_GUIDE.md       # Guide soumission jobs Spark
â””â”€â”€ README.md
```

---

## ðŸš€ DÃ©marrage Rapide

### 1ï¸âƒ£ PrÃ©requis

- Docker Desktop + Docker Compose
- Python 3.8+ (pour le producteur Kafka)
- 8 GB RAM minimum

### 2ï¸âƒ£ Lancer la stack Docker

```powershell
docker compose up -d
```

**Attendre ~60s** que tous les services soient **healthy** :

```powershell
docker compose ps
```

### 3ï¸âƒ£ CrÃ©er le rÃ©pertoire HDFS de base

```powershell
docker exec -it namenode hdfs dfs -mkdir -p /user/hdfs/traffic
docker exec -it namenode hdfs dfs -chown -R hdfs:hdfs /user/hdfs/traffic
```

### 4ï¸âƒ£ Lancer le producteur (gÃ©nÃ¨re des Ã©vÃ©nements)

```powershell
python scripts/kafka_producer.py
```

### 5ï¸âƒ£ VÃ©rifier que le consumer Ã©crit dans HDFS

```powershell
docker logs -f consumer
```

**Logs attendus** :

```
Consumer Kafka initialisÃ© avec bootstrap.servers=kafka:9093
Ã‰crit 50 messages dans /user/hdfs/traffic/year=2026/month=01/day=11/zone=Centre-Ville/traffic_*.jsonl
```

### 6ï¸âƒ£ Soumettre le job Spark (KPIs)

```powershell
# Copier le script
docker cp scripts/spark_traffic_processing.py spark-master:/tmp/

# Soumettre le job
docker exec -it spark-master /opt/spark/bin/spark-submit `
    --master spark://spark-master:7077 `
    --deploy-mode client `
    --executor-memory 2g `
    --total-executor-cores 2 `
    /tmp/spark_traffic_processing.py
```

### 7ï¸âƒ£ Tester l'API

```powershell
Invoke-WebRequest -Uri "http://localhost:8000/traffic/zones" -UseBasicParsing | Select-Object -ExpandProperty Content
```

### 8ï¸âƒ£ AccÃ©der Ã  Grafana

- URL : **http://localhost:3000** (admin/admin)
- Installer plugin : `docker exec -it grafana grafana-cli plugins install simpod-json-datasource`
- Configurer Data Source : `http://host.docker.internal:8000`
- CrÃ©er dashboard (voir `GRAFANA_GUIDE.md`)

---

## ðŸ“Š Pipeline de DonnÃ©es

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ traffic_data_   â”‚â”€â”€â”€â”€â”€â–¶â”‚  Kafka   â”‚â”€â”€â”€â”€â”€â–¶â”‚   HDFS   â”‚
â”‚ generator.py    â”‚      â”‚  Topic   â”‚      â”‚ (JSON L) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚
                                                  â–¼
                                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                           â”‚  Spark   â”‚
                                           â”‚  (KPIs)  â”‚
                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚
                                                  â–¼
                                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                           â”‚  Parquet â”‚
                                           â”‚ Analyticsâ”‚
                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚
                                                  â–¼
                                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                           â”‚ FastAPI  â”‚
                                           â”‚   API    â”‚
                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚
                                                  â–¼
                                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                           â”‚ Grafana  â”‚
                                           â”‚Dashboard â”‚
                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“Š Ã‰tapes RÃ©alisÃ©es

### âœ… Ã‰tape 1 â€“ GÃ©nÃ©ration de DonnÃ©es RÃ©alistes

**Fichier** : `scripts/traffic_data_generator.py`

GÃ©nÃ¨re des Ã©vÃ©nements JSON simulant le trafic urbain avec :

- 20 capteurs (IDs 1-20)
- 4 zones : Centre-Ville, PÃ©riphÃ©rie, Quartier-RÃ©sidentiel, Zone-Industrielle
- 4 types de routes : autoroute, avenue, rue, boulevard
- Patterns temporels : heures de pointe (7h-9h, 17h-20h), normales, nuit
- Anomalies : accidents (5% probabilitÃ©) avec baisse de vitesse et hausse d'occupation

**Format JSON** :

```json
{
  "sensor_id": 12,
  "timestamp": "2026-01-11T15:17:32.123456+00:00",
  "zone": "Centre-Ville",
  "road_type": "avenue",
  "vehicle_count": 87,
  "average_speed": 42,
  "occupancy_rate": 58
}
```

---

### âœ… Ã‰tape 2 â€“ Ingestion Kafka

**Fichier** : `scripts/kafka_producer.py`

- Producteur Kafka avec `confluent-kafka`
- Topic : `traffic-events`
- `acks='all'` : garantit la livraison
- Intervalle : 2 secondes entre chaque Ã©vÃ©nement
- Logs : `Message envoyÃ© au topic traffic-events : 12 - Centre-Ville`

---

### âœ… Ã‰tape 3 â€“ Consommation Kafka

**Fichier** : `kafka_to_hdfs.py`

- Consumer Group : `hdfs-consumer-group`
- Auto-offset : `earliest` (relit depuis le dÃ©but si nouveau groupe)
- Service Docker `consumer` qui tourne en continu

---

### âœ… Ã‰tape 4 â€“ Stockage HDFS PartitionnÃ©

**Fichier** : `scripts/kafka_to_hdfs.py`

**CaractÃ©ristiques** :

- **Micro-batching** : 50 messages OU 30 secondes
- **Format** : JSON Lines (`.jsonl`)
- **Partitionnement dynamique** :
  ```
  /user/hdfs/traffic/
    year=2026/
      month=01/
        day=11/
          zone=Centre-Ville/
            traffic_20260111151732.jsonl
          zone=PÃ©riphÃ©rie/
            traffic_20260111151755.jsonl
  ```
- **Un fichier par zone et par batch** (Ã©vite les "petits fichiers")

---

### âœ… Ã‰tape 5 â€“ Traitement Batch avec Spark

**Fichier** : `scripts/spark_traffic_processing.py`

**Objectif** : Transformer les donnÃ©es brutes HDFS en KPIs analytiques.

**Architecture** :

- **Lecture** : Fichiers JSON Lines depuis `/user/hdfs/traffic/*/*/*/*/*.jsonl`
- **Session Spark** : `spark://spark-master:7077` (mode cluster)
- **Nettoyage** :
  - Filtrage : `speed >= 0` ET `occupancy_rate <= 100`
  - DÃ©duplications : sur `sensor_id` + `timestamp`
- **UDF** : `congestion_level(occupancy, speed)` â†’ 4 niveaux :
  - **Fluide** : occupancy < 40% ET speed > 50 km/h
  - **ModÃ©rÃ©** : 40% â‰¤ occupancy < 70% OU 30 < speed â‰¤ 50
  - **Dense** : 70% â‰¤ occupancy < 85% OU 20 < speed â‰¤ 30
  - **BloquÃ©** : occupancy â‰¥ 85% OU speed â‰¤ 20

**KPIs calculÃ©s** :

1. **Vitesse moyenne par `road_type`** â†’ `/data/analytics/traffic/kpi_road_type`
2. **Occupation moyenne par `zone`** (partitionnÃ©) â†’ `/data/analytics/traffic/kpi_zone/zone=...`
3. **VÃ©hicules par heure** â†’ `/data/analytics/traffic/kpi_hourly`
4. **RÃ©partition congestion** â†’ `/data/analytics/traffic/kpi_congestion`

**Sortie** :

- **Parquet** partitionnÃ© (analytics)
- **CSV** Ã©chantillon (1000 lignes pour debugging) â†’ `/data/processed/traffic`

---

### âœ… Ã‰tape 6 â€“ API REST et Visualisation

**Fichiers** : `api/api_analytics.py`, `GRAFANA_GUIDE.md`

**API FastAPI** (service Docker `api-analytics`) :

- **Port** : 8000
- **Endpoints REST** :
  - `GET /traffic/zones` : Volume par zone
  - `GET /traffic/congestion` : Top 5 zones congestionnÃ©es
  - `GET /traffic/speed` : Vitesse par road_type
  - `GET /traffic/trends` : VÃ©hicules par heure
- **Cache** : 5 minutes
- **CORS** : ActivÃ© pour Grafana
- **Gestion partitions Spark** : Extraction automatique de la colonne `zone` depuis le chemin

**Grafana Dashboard** :

- Plugin : `simpod-json-datasource`
- Data Source : `http://host.docker.internal:8000`
- **4 Panels** :
  1. **Stat** : Trafic global (3062 Ã©vÃ©nements)
  2. **Table** : Top zones congestionnÃ©es (Centre-Ville, PÃ©riphÃ©rie, etc.)
  3. **Bar Chart** : Vitesse par type de route
  4. **Time Series** : VÃ©hicules par heure



![dashbord](captures/e6-dashbord.png "dachbord")


---

## ðŸ› ï¸ ProblÃ¨mes RÃ©solus

| ProblÃ¨me                                                         | Cause                                                                       | Solution                                                         |
| ---------------------------------------------------------------- | --------------------------------------------------------------------------- | ---------------------------------------------------------------- |
| **Permission denied HDFS**                                       | Le rÃ©pertoire `/data/raw/traffic` appartenait Ã  `root`.                     | Utiliser `/user/hdfs/traffic` (propriÃ©taire : `hdfs`).           |
| **`socket.gaierror` DataNode**                                   | Le consumer Windows ne rÃ©solvait pas le hostname du DataNode Docker.        | ExÃ©cuter le consumer**dans Docker** (service `consumer`).        |
| **`Connection refused localhost:9093`**                          | Kafka annonÃ§ait `localhost:9093` au lieu de `kafka:9093`.                   | Corriger `KAFKA_ADVERTISED_LISTENERS` dans `docker-compose.yml`. |
| **Consumer lit `localhost` malgrÃ© `KAFKA_BOOTSTRAP=kafka:9093`** | Le consumer Kafka Ã©tait crÃ©Ã© au niveau module (avant lecture des env vars). | DÃ©placer la crÃ©ation du consumer**dans `main()`**.               |
| **`spark-submit` introuvable**                                   | L'image Spark n'a pas `spark-submit` dans le `$PATH`.                       | Utiliser `/opt/spark/bin/spark-submit`.                          |
| **Erreur "seek" lecture Parquet API**                            | `pyarrow` ne peut pas lire depuis un stream HDFS non-seekable.              | Charger les fichiers en mÃ©moire avec `io.BytesIO`.               |
| **Zone affiche "Inconnu" dans l'API**                            | Spark partitionne par `zone=...`, la colonne n'est pas dans les Parquet.    | Extraire `zone` depuis le chemin de partition.                   |

---

## ðŸ“‹ Fichiers ClÃ©s

### `docker-compose.yml`

- **Kafka** : `KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://kafka:9093`
- **Service `consumer`** : ExÃ©cute `kafka_to_hdfs.py` automatiquement
- **Service `api`** : FastAPI sur port 8000

### `scripts/kafka_to_hdfs.py`

- Variables d'environnement lues correctement
- Consumer crÃ©Ã© **dans `main()`** (pas au niveau module)
- Gestion d'erreurs robuste pour la crÃ©ation de rÃ©pertoires HDFS

### `api/api_analytics.py`

- Lecture rÃ©cursive des partitions Spark
- Extraction de `zone` depuis le chemin
- Cache 5 minutes pour optimiser les performances

---

## ðŸ”§ Commandes Utiles

```powershell
# RedÃ©marrer la stack complÃ¨te
docker compose down
docker compose up -d

# Voir les logs d'un service
docker logs -f consumer
docker logs -f api-analytics
docker logs -f kafka
docker logs -f namenode

# VÃ©rifier l'Ã©tat des services
docker compose ps

# Supprimer les donnÃ©es HDFS (pour repartir de zÃ©ro)
docker exec -it namenode hdfs dfs -rm -r -skipTrash /user/hdfs/traffic
docker exec -it namenode hdfs dfs -mkdir -p /user/hdfs/traffic
docker exec -it namenode hdfs dfs -chown -R hdfs:hdfs /user/hdfs/traffic

# Lister les topics Kafka
docker exec -it kafka kafka-topics --bootstrap-server localhost:9093 --list

# Consommer le topic manuellement
docker exec -it kafka kafka-console-consumer \
    --bootstrap-server localhost:9093 \
    --topic traffic-events \
    --from-beginning \
    --max-messages 5

# VÃ©rifier KPIs Parquet
docker exec -it namenode hdfs dfs -ls /data/analytics/traffic/kpi_zone

# Tester l'API
Invoke-WebRequest -Uri "http://localhost:8000/traffic/zones" -UseBasicParsing
```

---

## ðŸŽ¯ Validation ComplÃ¨te

### âœ… Ã‰tape 4 - Stockage HDFS

```powershell
docker exec -it namenode hdfs dfs -ls /user/hdfs/traffic/year=2026/month=01/day=11
docker exec -it namenode hdfs dfs -cat /user/hdfs/traffic/year=2026/month=01/day=11/zone=Centre-Ville/traffic_*.jsonl | Select-Object -First 5
```

### âœ… Ã‰tape 5 - Traitement Spark

```powershell
docker exec -it namenode hdfs dfs -ls /data/analytics/traffic/kpi_congestion
docker exec namenode hdfs dfs -cat /data/processed/traffic/part-00000-*.csv > results.csv
Get-Content results.csv -Head 20
```

### âœ… Ã‰tape 6 - API et Grafana

```powershell
Invoke-WebRequest -Uri "http://localhost:8000/traffic/zones" -UseBasicParsing | Select-Object -ExpandProperty Content
```

**Dashboard Grafana** : http://localhost:3000
**Screenshot** : `captures/e6-dashbord.png` (4 panels opÃ©rationnels)

---

## ðŸŽ‰ Prochaine Ã‰tape

### Ã‰tape 7 â€“ Orchestration Airflow

- DAG quotidien : traitement batch Spark automatique
- DAG de monitoring : vÃ©rification santÃ© du pipeline
- Alertes en cas d'Ã©chec

---

## ðŸ“Œ RÃ¨gles de DÃ©veloppement

1. **Code** : clair, simple, directement utilisable
2. **DÃ©pendances** : uniquement la stack dÃ©finie (pas d'ajouts non validÃ©s)
3. **SÃ©curitÃ©** : variables d'environnement (pas de secrets en dur)
4. **Exceptions** : gestion propre avec logs explicites
5. **Commentaires** : expliquer le "Pourquoi", pas le "Quoi"

---

## ðŸ”— Liens Utiles

- **HDFS NameNode UI** : http://localhost:9870
- **Spark Master UI** : http://localhost:8080
- **Spark Worker UI** : http://localhost:8081
- **API Analytics** : http://localhost:8000
- **Grafana** : http://localhost:3000
- **Airflow** : http://localhost:8085

---

**Projet rÃ©alisÃ© par** : Mohamed BOULAA LAM
**Contact** : [GitHub](https://github.com/MohamedBOULAALAM/SmartCity_Traffic_Pipeline)
**Date** : Janvier 2026
