# SmartCity Traffic Pipeline â€“ Guide de dÃ©marrage et de test

## ğŸ¯ Objectif
Ce dÃ©pÃ´t implÃ©mente un pipeline **Big Data** complet pour analyser le trafic urbainâ€¯:
1. **GÃ©nÃ©ration de donnÃ©es** rÃ©alistes (`traffic_data_generator.py`).
2. **Ingestion** dans Kafka (`kafka_producer.py`).
3. **Consommation** et stockage dans HDFS (`kafka_to_hdfs.py`).
4. (Ã€ venir) traitement Spark, visualisation Grafana, etc.

Le prÃ©sent guide vous montre comment **dÃ©marrer** la stack Docker, **gÃ©nÃ©rer** des Ã©vÃ©nements, **les consommer** et **vÃ©rifier** quâ€™ils sont bien Ã©crits dans HDFS.

---

## ğŸ“¦ PrÃ©requis
| Outil | Version recommandÃ©e |
|-------|--------------------|
| Docker & Dockerâ€‘Compose | >=â€¯24.0 |
| Python | 3.8+ (utilisez le virtualenv fourni) |
| `docker` doit Ãªtre accessible depuis le terminal PowerShell (ou CMD) |

> **Note**â€¯: le projet utilise un environnement virtuel (`.venv`).

---

## ğŸ—‚ï¸ Structure du projet
```
SmartCity_Traffic_Pipeline/
â”œâ”€ docker-compose.yml          # stack complÃ¨te (Kafka, Zookeeper, HDFS, Spark, Airflow, Grafana)
â”œâ”€ .env                       # variables dâ€™environnement pour Docker
â”œâ”€ scripts/
â”‚   â”œâ”€ traffic_data_generator.py   # gÃ©nÃ©ration dâ€™Ã©vÃ©nements JSON
â”‚   â”œâ”€ kafka_producer.py           # producteur Kafka
â”‚   â””â”€ kafka_to_hdfs.py            # consommateur â†’ HDFS
â””â”€ README.md                    # <â€‘â€‘ vous Ãªtes ici
```

---

## ğŸš€ DÃ©marrage de la stack Docker
```powershell
# 1ï¸âƒ£ Cloner / ouvrir le rÃ©pertoire du projet
cd C:\Users\Admin\Desktop\SmartCity_Traffic_Pipeline

# 2ï¸âƒ£ CrÃ©er/activer lâ€™environnement virtuel (si ce nâ€™est pas dÃ©jÃ  fait)
python -m venv .venv
& .venv\Scripts\Activate.ps1   # PowerShell
# (ou `source .venv/Scripts/activate` sous Gitâ€‘Bash)

# 3ï¸âƒ£ Installer les dÃ©pendances Python
pip install -r requirements.txt   # (confluentâ€‘kafka, hdfs, etc.)

# 4ï¸âƒ£ Lancer les services Docker
docker compose up -d   # dÃ©marre Kafka, Zookeeper, HDFS (namenode & datanode), Spark, Airflow, Grafana

# 5ï¸âƒ£ VÃ©rifier que les conteneurs sont en cours dâ€™exÃ©cution
docker ps   # vous devez voir au moins `namenode`, `kafka`, `zookeeper`
```

> **Astuce**â€¯: si le service `pgadmin` pose problÃ¨me, il a Ã©tÃ© commentÃ© dans `dockerâ€‘compose.yml` â€“ il nâ€™est pas requis pour le pipeline.

---

## ğŸ“‚ PrÃ©parer HDFS
Le compte `hdfs` ne possÃ¨de les droits dâ€™Ã©criture que sous `/user/hdfs`. CrÃ©ez le rÃ©pertoire de baseâ€¯:
```powershell
docker exec -it namenode hdfs dfs -mkdir -p /user/hdfs/traffic
```
> Cette commande ne produit aucune sortie lorsquâ€™elle rÃ©ussit.

---

## â–¶ï¸ Ã‰tape 1 â€“ GÃ©nÃ©rer et publier des Ã©vÃ©nements Kafka
Ouvrez **un terminal** et lancez le producteurâ€¯:
```powershell
python scripts/kafka_producer.py
```
Vous verrez des lignes du typeâ€¯:
```
2026-01-09 01:06:09 INFO Message envoyÃ© au topic traffic-events : 11 - Zone-Industrielle
```
Le producteur tourne en boucle (ou pendant le temps dÃ©fini par `GEN_SLEEP`). Laissezâ€‘le actif pendant le test.

---

## â–¶ï¸ Ã‰tape 2 â€“ Consommer et Ã©crire dans HDFS
Dans **un second terminal**, dÃ©marrez le consommateurâ€¯:
```powershell
python scripts/kafka_to_hdfs.py
```
Logs attendusâ€¯:
```
2026-01-09 01:02:23 INFO Fetching status for '/user/hdfs/traffic/year=2026/month=01/day=09/zone=Quartier-RÃ©sidentiel/'
2026-01-09 01:02:23 INFO Creating directories to '/user/hdfs/traffic/year=2026/month=01/day=09/zone=Quartier-RÃ©sidentiel/'
2026-01-09 01:02:23 INFO Ã‰crit 50 messages dans /user/hdfs/traffic/.../traffic_20260109010223.jsonl
```
Le script crÃ©e les dossiers **year / month / day / zone** et Ã©crit les fichiers au format **JSONâ€‘Lines**.

---

## ğŸ” VÃ©rifier le rÃ©sultat dans HDFS
AprÃ¨s quelques secondes (ou aprÃ¨s le batch de 50â€¯msg), listez le rÃ©pertoireâ€¯:
```powershell
# Exemple pour le jour 09/01/2026 et la zone "Centre-Ville"
docker exec -it namenode hdfs dfs -ls /user/hdfs/traffic/year=2026/month=01/day=09/zone=Centre-Ville
```
Vous devriez voir un ou plusieurs fichiers `traffic_*.jsonl`.

Pour afficher le contenuâ€¯:
```powershell
docker exec -it namenode hdfs dfs -cat /user/hdfs/traffic/year=2026/month=01/day=09/zone=Centre-Ville/traffic_*.jsonl
```
Chaque ligne ressemble Ã â€¯:
```json
{"sensor_id":12,"timestamp":"2026-01-09T01:06:10.123456+00:00","zone":"Centre-Ville","road_type":"avenue","vehicle_count":87,"average_speed":42,"occupancy_rate":58}
```

---

## ğŸ› ï¸ DÃ©pannage frÃ©quent
| Symptom | Cause probable | Solution |
|---------|----------------|----------|
| `Permission denied: user=hdfs, access=WRITE` | Le rÃ©pertoire de base nâ€™est pas sous `/user/hdfs` ou nâ€™existe pas. | CrÃ©ezâ€‘le avec `docker exec -it namenode hdfs dfs -mkdir -p /user/hdfs/traffic`.
| Aucun log du consommateur | Le producteur nâ€™est pas en cours dâ€™exÃ©cution ou le topic est vide. | Lancez `kafka_producer.py` puis vÃ©rifiez le topic avec `docker exec -it kafka kafka-console-consumer â€¦`.
| `docker exec â€¦ hdfs dfs -ls` renvoie â€œNo such file or directoryâ€ | Le batch nâ€™a pas encore atteint `BATCH_SIZE` ou `BATCH_TIMEOUT`. | Attendez 30â€¯s ou augmentez le dÃ©bit du producteur.
| `docker exec â€¦ kafka-console-consumer` Ã©choue sous PowerShell | Utilisation de `\` pour la continuation de ligne. | Remplacez les `\` par le backâ€‘tick `` ` `` ou Ã©crivez la commande sur une seule ligne.

---

## ğŸ“¦ Nettoyage (optionnel)
Pour repartir dâ€™un Ã©tat viergeâ€¯:
```powershell
# Supprimer les dossiers HDFS crÃ©Ã©s
docker exec -it namenode hdfs dfs -rm -r -skipTrash /user/hdfs/traffic
# RedÃ©marrer la stack (si vous avez modifiÃ© des images)
docker compose down -v && docker compose up -d
```

---

## ğŸ‰ Vous Ãªtes prÃªtsâ€¯!
Vous avez maintenantâ€¯:
- Une stack Docker fonctionnelle (Kafka, HDFS, â€¦).
- Un producteur qui gÃ©nÃ¨re des Ã©vÃ©nements de trafic rÃ©alistes.
- Un consommateur qui les Ã©crit dans HDFS avec partitionnement dynamique.

Les prochaines Ã©tapes du projet consisteront Ã  **traiter** ces donnÃ©es avec Spark et Ã  **visualiser** les KPI dans Grafana.

---

*Ce guide a Ã©tÃ© rÃ©digÃ© par lâ€™assistantâ€¯*Antigravity*â€¯dans le cadre du projet SmartCity Traffic Pipeline.*
