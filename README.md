# SmartCity Traffic Analytics â€“ Pipeline Big Data End-to-End

## ğŸ¯ Objectif du Projet

Pipeline Big Data complet pour analyser le trafic urbain en temps rÃ©el :
1. **GÃ©nÃ©ration** de donnÃ©es de trafic rÃ©alistes
2. **Ingestion** via Kafka
3. **Stockage** partitionnÃ© dans HDFS (Data Lake)
4. **Traitement** avec Spark (KPIs de congestion)
5. **Visualisation** avec Grafana

**Ã‰tat actuel** : âœ… **Ã‰tapes 1-4 complÃ¨tes** (GÃ©nÃ©ration â†’ Kafka â†’ HDFS)

---

## ğŸ› ï¸ Stack Technique (Docker)

| Service           | Version | Port       | RÃ´le                      |
| ----------------- | ------- | ---------- | ------------------------- |
| **Kafka**         | 7.5.0   | 9093       | Broker de messages        |
| **Zookeeper**     | 7.5.0   | 2181       | Coordination Kafka        |
| **HDFS Namenode** | 3.2.1   | 9870       | MÃ©tadonnÃ©es HDFS          |
| **HDFS Datanode** | 3.2.1   | -          | Stockage blocs HDFS       |
| **Spark Master**  | 3.5.1   | 8080, 7077 | Orchestration traitements |
| **Spark Worker**  | 3.5.1   | 8081       | ExÃ©cution jobs Spark      |
| **Airflow**       | 2.9.3   | 8085       | Orchestration DAGs        |
| **PostgreSQL**    | 13      | 5432       | MÃ©tadonnÃ©es Airflow       |
| **Grafana**       | latest  | 3000       | Visualisation             |

---

## ğŸ“‚ Architecture du Projet

```
SmartCity_Traffic_Pipeline/
â”œâ”€â”€ docker-compose.yml          # Stack complÃ¨te
â”œâ”€â”€ .env                        # Variables d'environnement
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ traffic_data_generator.py   # GÃ©nÃ©ration d'Ã©vÃ©nements
â”‚   â”œâ”€â”€ kafka_producer.py           # Producteur Kafka
â”‚   â””â”€â”€ kafka_to_hdfs.py            # Consommateur â†’ HDFS
â”œâ”€â”€ dags/                       # DAGs Airflow (Ã  venir)
â”œâ”€â”€ logs/                       # Logs Airflow
â””â”€â”€ README.md
```

---

## ğŸš€ DÃ©marrage Rapide

### 1ï¸âƒ£ PrÃ©requis
- Docker Desktop + Docker Compose
- Python 3.8+

### 2ï¸âƒ£ Lancer la stack Docker
```powershell
docker compose up -d
```

**Attendre ~60s** que tous les services soient **healthy** :
```powershell
docker compose ps
```

### 3ï¸âƒ£ CrÃ©er le rÃ©pertoire HDFS de base
```powershell
docker exec -it namenode hdfs dfs -mkdir -p /user/hdfs/traffic
docker exec -it namenode hdfs dfs -chown -R hdfs:hdfs /user/hdfs/traffic
```

### 4ï¸âƒ£ Lancer le producteur (gÃ©nÃ¨re des Ã©vÃ©nements)
```powershell
python scripts/kafka_producer.py
```

### 5ï¸âƒ£ VÃ©rifier que le consumer Ã©crit dans HDFS
```powershell
docker logs -f consumer
```

**Logs attendus** :
```
Consumer Kafka initialisÃ© avec bootstrap.servers=kafka:9093
Ã‰crit 50 messages dans /user/hdfs/traffic/year=2026/month=01/day=11/zone=Centre-Ville/traffic_*.jsonl
```

### 6ï¸âƒ£ VÃ©rifier les fichiers HDFS
```powershell
# Lister les fichiers
docker exec -it namenode hdfs dfs -ls /user/hdfs/traffic/year=2026/month=01/day=11/zone=Centre-Ville

# Afficher le contenu
docker exec -it namenode hdfs dfs -cat /user/hdfs/traffic/year=2026/month=01/day=11/zone=Centre-Ville/traffic_*.jsonl
```

**RÃ©sultat attendu** : lignes JSON avec `sensor_id`, `timestamp`, `zone`, `vehicle_count`, etc.

---

## ğŸ“Š Ã‰tapes RÃ©alisÃ©es

### âœ… Ã‰tape 1 â€“ GÃ©nÃ©ration de DonnÃ©es RÃ©alistes
**Fichier** : `scripts/traffic_data_generator.py`

GÃ©nÃ¨re des Ã©vÃ©nements JSON simulant le trafic urbain avec :
- 20 capteurs (IDs 1-20)
- 4 zones : Centre-Ville, PÃ©riphÃ©rie, Quartier-RÃ©sidentiel, Zone-Industrielle
- Patterns temporels : heures de pointe (7h-9h, 17h-20h), normales, nuit
- Anomalies : accidents (5% probabilitÃ©) avec baisse de vitesse et hausse d'occupation

**Format JSON** :
```json
{
  "sensor_id": 12,
  "timestamp": "2026-01-11T15:17:32.123456+00:00",
  "zone": "Centre-Ville",
  "road_type": "avenue",
  "vehicle_count": 87,
  "average_speed": 42,
  "occupancy_rate": 58
}
```

---

### âœ… Ã‰tape 2 â€“ Ingestion Kafka
**Fichier** : `scripts/kafka_producer.py`

- Producteur Kafka avec `confluent-kafka`
- Topic : `traffic-events`
- `acks='all'` : garantit la livraison
- Logs : `Message envoyÃ© au topic traffic-events : 12 - Centre-Ville`

---

### âœ… Ã‰tape 3 â€“ Consommation Kafka
**Fichier** : `kafka_to_hdfs.py`

- Consumer Group : `hdfs-consumer-group`
- Auto-offset : `earliest` (relit depuis le dÃ©but si nouveau groupe)

---

### âœ… Ã‰tape 4 â€“ Stockage HDFS PartitionnÃ©
**Fichier** : `scripts/kafka_to_hdfs.py`

**CaractÃ©ristiques** :
- **Micro-batching** : 50 messages OU 30 secondes
- **Format** : JSON Lines (`.jsonl`)
- **Partitionnement dynamique** :
  ```
  /user/hdfs/traffic/
    year=2026/
      month=01/
        day=11/
          zone=Centre-Ville/
            traffic_20260111151732.jsonl
          zone=PÃ©riphÃ©rie/
            traffic_20260111151755.jsonl
  ```
- **Un fichier par zone et par batch** (Ã©vite les "petits fichiers")

---

## ğŸ› ï¸ ProblÃ¨mes RÃ©solus

| ProblÃ¨me                                                         | Cause                                                                       | Solution                                                         |
| ---------------------------------------------------------------- | --------------------------------------------------------------------------- | ---------------------------------------------------------------- |
| **Permission denied HDFS**                                       | Le rÃ©pertoire `/data/raw/traffic` appartenait Ã  `root`.                     | Utiliser `/user/hdfs/traffic` (propriÃ©taire : `hdfs`).           |
| **`socket.gaierror` DataNode**                                   | Le consumer Windows ne rÃ©solvait pas le hostname du DataNode Docker.        | ExÃ©cuter le consumer **dans Docker** (service `consumer`).       |
| **`Connection refused localhost:9093`**                          | Kafka annonÃ§ait `localhost:9093` au lieu de `kafka:9093`.                   | Corriger `KAFKA_ADVERTISED_LISTENERS` dans `docker-compose.yml`. |
| **Consumer lit `localhost` malgrÃ© `KAFKA_BOOTSTRAP=kafka:9093`** | Le consumer Kafka Ã©tait crÃ©Ã© au niveau module (avant lecture des env vars). | DÃ©placer la crÃ©ation du consumer **dans `main()`**.              |

---

## ğŸ“‹ Fichiers ClÃ©s ModifiÃ©s

### `docker-compose.yml`
- **Kafka** : `KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://kafka:9093`
- **Service `consumer`** : conteneur Python qui exÃ©cute `kafka_to_hdfs.py` automatiquement au dÃ©marrage

### `scripts/kafka_to_hdfs.py`
- Variables d'environnement lues correctement
- Consumer crÃ©Ã© **dans `main()`** (pas au niveau module)
- Gestion d'erreurs robuste pour la crÃ©ation de rÃ©pertoires HDFS

---

## ğŸ”§ Commandes Utiles

```powershell
# RedÃ©marrer la stack complÃ¨te
docker compose down
docker compose up -d

# Voir les logs d'un service
docker logs -f consumer
docker logs -f kafka
docker logs -f namenode

# VÃ©rifier l'Ã©tat des services
docker compose ps

# Supprimer les donnÃ©es HDFS (pour repartir de zÃ©ro)
docker exec -it namenode hdfs dfs -rm -r -skipTrash /user/hdfs/traffic
docker exec -it namenode hdfs dfs -mkdir -p /user/hdfs/traffic
docker exec -it namenode hdfs dfs -chown -R hdfs:hdfs /user/hdfs/traffic

# Lister les topics Kafka
docker exec -it kafka kafka-topics --bootstrap-server localhost:9093 --list

# Consommer le topic manuellement
docker exec -it kafka kafka-console-consumer \
    --bootstrap-server localhost:9093 \
    --topic traffic-events \
    --from-beginning \
    --max-messages 5
```

---

## ğŸ¯ Prochaines Ã‰tapes

### Ã‰tape 5 â€“ Traitement Spark
- Lire les fichiers `.jsonl` depuis HDFS
- Calculer des KPIs :
  - DÃ©bit moyen par zone
  - Vitesse moyenne par heure
  - DÃ©tection de congestion (occupancy > 80%, speed < 20 km/h)
- Ã‰crire les rÃ©sultats dans une base SQL ou HDFS

### Ã‰tape 6 â€“ Visualisation Grafana
- API Python (Flask/FastAPI) exposant les KPIs
- Dashboard Grafana affichant :
  - Trafic en temps rÃ©el par zone
  - Heatmap de congestion
  - Alertes (accidents, embouteillages)

### Ã‰tape 7 â€“ Orchestration Airflow
- DAG quotidien : traitement batch Spark
- DAG de monitoring : vÃ©rification santÃ© du pipeline

---

## ğŸ“Œ RÃ¨gles de DÃ©veloppement

1. **Code** : clair, simple, directement utilisable
2. **DÃ©pendances** : uniquement la stack dÃ©finie (pas d'ajouts non validÃ©s)
3. **SÃ©curitÃ©** : variables d'environnement (pas de secrets en dur)
4. **Exceptions** : gestion propre avec logs explicites
5. **Commentaires** : expliquer le "Pourquoi", pas le "Quoi"

---

## ğŸ‰ Validation Ã‰tape 4

**Checklist** :
- [x] Stack Docker fonctionnelle
- [x] Producteur Kafka envoie des Ã©vÃ©nements
- [x] Consumer Docker consomme et Ã©crit dans HDFS
- [x] RÃ©pertoires HDFS crÃ©Ã©s dynamiquement (`year/month/day/zone`)
- [x] Fichiers `.jsonl` prÃ©sents et lisibles
- [x] Partitionnement optimisÃ© (un fichier par zone et par batch)

**Commande de validation finale** :
```powershell
docker exec -it namenode hdfs dfs -cat /user/hdfs/traffic/year=2026/month=01/day=11/zone=Centre-Ville/traffic_*.jsonl | head -n 5
```

Si vous voyez du JSON valide â†’ **Ã‰tape 4 RÃ‰USSIE** âœ…

---

**Projet rÃ©alisÃ© par** : Mohamed BOULAA LAM  
**Contact** : [GitHub](https://github.com/MohamedBOULAALAM/SmartCity_Traffic_Pipeline)  
**Date** : Janvier 2026
