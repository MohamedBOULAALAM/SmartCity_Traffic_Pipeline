# SmartCity Traffic Analytics ‚Äì Pipeline Big Data End-to-End

## üéØ Objectif du Projet

Pipeline Big Data complet pour analyser le trafic urbain en temps r√©el :
1. **G√©n√©ration** de donn√©es de trafic r√©alistes
2. **Ingestion** via Kafka
3. **Stockage** partitionn√© dans HDFS (Data Lake)
4. **Traitement** avec Spark (KPIs de congestion)
5. **Visualisation** avec Grafana

**√âtat actuel** : ‚úÖ **√âtapes 1-6 compl√®tes** (G√©n√©ration ‚Üí Kafka ‚Üí HDFS ‚Üí Spark ‚Üí API)

---

## üõ†Ô∏è Stack Technique (Docker)

| Service           | Version | Port       | R√¥le                      |
| ----------------- | ------- | ---------- | ------------------------- |
| **Kafka**         | 7.5.0   | 9093       | Broker de messages        |
| **Zookeeper**     | 7.5.0   | 2181       | Coordination Kafka        |
| **HDFS Namenode** | 3.2.1   | 9870       | M√©tadonn√©es HDFS          |
| **HDFS Datanode** | 3.2.1   | -          | Stockage blocs HDFS       |
| **Spark Master**  | 3.5.1   | 8080, 7077 | Orchestration traitements |
| **Spark Worker**  | 3.5.1   | 8081       | Ex√©cution jobs Spark      |
| **Airflow**       | 2.9.3   | 8085       | Orchestration DAGs        |
| **PostgreSQL**    | 13      | 5432       | M√©tadonn√©es Airflow       |
| **Grafana**       | latest  | 3000       | Visualisation             |

---

## üìÇ Architecture du Projet

```
SmartCity_Traffic_Pipeline/
‚îú‚îÄ‚îÄ docker-compose.yml          # Stack compl√®te
‚îú‚îÄ‚îÄ .env                        # Variables d'environnement
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ traffic_data_generator.py   # G√©n√©ration d'√©v√©nements
‚îÇ   ‚îú‚îÄ‚îÄ kafka_producer.py           # Producteur Kafka
‚îÇ   ‚îî‚îÄ‚îÄ kafka_to_hdfs.py            # Consommateur ‚Üí HDFS
‚îú‚îÄ‚îÄ dags/                       # DAGs Airflow (√† venir)
‚îú‚îÄ‚îÄ logs/                       # Logs Airflow
‚îî‚îÄ‚îÄ README.md
```

---

## üöÄ D√©marrage Rapide

### 1Ô∏è‚É£ Pr√©requis
- Docker Desktop + Docker Compose
- Python 3.8+

### 2Ô∏è‚É£ Lancer la stack Docker
```powershell
docker compose up -d
```

**Attendre ~60s** que tous les services soient **healthy** :
```powershell
docker compose ps
```

### 3Ô∏è‚É£ Cr√©er le r√©pertoire HDFS de base
```powershell
docker exec -it namenode hdfs dfs -mkdir -p /user/hdfs/traffic
docker exec -it namenode hdfs dfs -chown -R hdfs:hdfs /user/hdfs/traffic
```

### 4Ô∏è‚É£ Lancer le producteur (g√©n√®re des √©v√©nements)
```powershell
python scripts/kafka_producer.py
```

### 5Ô∏è‚É£ V√©rifier que le consumer √©crit dans HDFS
```powershell
docker logs -f consumer
```

**Logs attendus** :
```
Consumer Kafka initialis√© avec bootstrap.servers=kafka:9093
√âcrit 50 messages dans /user/hdfs/traffic/year=2026/month=01/day=11/zone=Centre-Ville/traffic_*.jsonl
```

### 6Ô∏è‚É£ V√©rifier les fichiers HDFS
```powershell
# Lister les fichiers
docker exec -it namenode hdfs dfs -ls /user/hdfs/traffic/year=2026/month=01/day=11/zone=Centre-Ville

# Afficher le contenu
docker exec -it namenode hdfs dfs -cat /user/hdfs/traffic/year=2026/month=01/day=11/zone=Centre-Ville/traffic_*.jsonl
```

**R√©sultat attendu** : lignes JSON avec `sensor_id`, `timestamp`, `zone`, `vehicle_count`, etc.

---

## üìä √âtapes R√©alis√©es

### ‚úÖ √âtape 1 ‚Äì G√©n√©ration de Donn√©es R√©alistes
**Fichier** : `scripts/traffic_data_generator.py`

G√©n√®re des √©v√©nements JSON simulant le trafic urbain avec :
- 20 capteurs (IDs 1-20)
- 4 zones : Centre-Ville, P√©riph√©rie, Quartier-R√©sidentiel, Zone-Industrielle
- Patterns temporels : heures de pointe (7h-9h, 17h-20h), normales, nuit
- Anomalies : accidents (5% probabilit√©) avec baisse de vitesse et hausse d'occupation

**Format JSON** :
```json
{
  "sensor_id": 12,
  "timestamp": "2026-01-11T15:17:32.123456+00:00",
  "zone": "Centre-Ville",
  "road_type": "avenue",
  "vehicle_count": 87,
  "average_speed": 42,
  "occupancy_rate": 58
}
```

---

### ‚úÖ √âtape 2 ‚Äì Ingestion Kafka
**Fichier** : `scripts/kafka_producer.py`

- Producteur Kafka avec `confluent-kafka`
- Topic : `traffic-events`
- `acks='all'` : garantit la livraison
- Logs : `Message envoy√© au topic traffic-events : 12 - Centre-Ville`

---

### ‚úÖ √âtape 3 ‚Äì Consommation Kafka
**Fichier** : `kafka_to_hdfs.py`

- Consumer Group : `hdfs-consumer-group`
- Auto-offset : `earliest` (relit depuis le d√©but si nouveau groupe)

---

### ‚úÖ √âtape 4 ‚Äì Stockage HDFS Partitionn√©
**Fichier** : `scripts/kafka_to_hdfs.py`

**Caract√©ristiques** :
- **Micro-batching** : 50 messages OU 30 secondes
- **Format** : JSON Lines (`.jsonl`)
- **Partitionnement dynamique** :
  ```
  /user/hdfs/traffic/
    year=2026/
      month=01/
        day=11/
          zone=Centre-Ville/
            traffic_20260111151732.jsonl
          zone=P√©riph√©rie/
            traffic_20260111151755.jsonl
  ```
- **Un fichier par zone et par batch** (√©vite les "petits fichiers")

---

### ‚úÖ √âtape 5 ‚Äì Traitement Batch avec Spark
**Fichier** : `scripts/spark_traffic_processing.py`

**Objectif** : Transformer les donn√©es brutes HDFS en KPIs analytiques.

**Architecture** :
- **Lecture** : Fichiers JSON Lines depuis `/user/hdfs/traffic/*/*/*/*/*.jsonl`
- **Session Spark** : `spark://spark-master:7077` (mode cluster)
- **Nettoyage** :
  - Filtrage : `speed >= 0` ET `occupancy_rate <= 100`
  - D√©duplications : sur `sensor_id` + `timestamp`
- **UDF** : `congestion_level(occupancy, speed)` ‚Üí 4 niveaux :
  - **Fluide** : occupancy < 40% ET speed > 50 km/h
  - **Mod√©r√©** : 40% ‚â§ occupancy < 70% OU 30 < speed ‚â§ 50
  - **Dense** : 70% ‚â§ occupancy < 85% OU 20 < speed ‚â§ 30
  - **Bloqu√©** : occupancy ‚â• 85% OU speed ‚â§ 20

**KPIs calcul√©s** :
1. **Vitesse moyenne par `road_type`** ‚Üí `/data/analytics/traffic/kpi_road_type`
2. **Occupation moyenne par `zone`** (partitionn√©) ‚Üí `/data/analytics/traffic/kpi_zone/zone=...`
3. **V√©hicules par heure** ‚Üí `/data/analytics/traffic/kpi_hourly`
4. **R√©partition congestion** ‚Üí `/data/analytics/traffic/kpi_congestion`

**Sortie** :
- **Parquet** partitionn√© (analytics)
- **CSV** √©chantillon (1000 lignes pour debugging) ‚Üí `/data/processed/traffic`

**Exemple CSV** :
```csv
sensor_id,timestamp,zone,road_type,vehicle_count,average_speed,occupancy_rate,congestion_status
1,2026-01-11T14:09:14.880538+00:00,Centre-Ville,avenue,104,10,100,Bloqu√©
1,2026-01-11T14:10:24.272062+00:00,Centre-Ville,rue,110,56,30,Fluide
1,2026-01-11T14:10:22.226866+00:00,Zone-Industrielle,autoroute,97,58,70,Dense
```

**Soumission du job** :
```powershell
# Copier le script dans le conteneur
docker cp scripts/spark_traffic_processing.py spark-master:/tmp/

# Soumettre le job (chemin complet de spark-submit)
docker exec -it spark-master /opt/spark/bin/spark-submit \
    --master spark://spark-master:7077 \
    --deploy-mode client \
    --executor-memory 2g \
    --total-executor-cores 2 \
    /tmp/spark_traffic_processing.py
```

**V√©rification** :
```powershell
# Lister les KPIs Parquet
docker exec -it namenode hdfs dfs -ls /data/analytics/traffic/kpi_zone
docker exec -it namenode hdfs dfs -ls /data/analytics/traffic/kpi_congestion

# Lire les r√©sultats avec PySpark
docker exec -it spark-master /opt/spark/bin/pyspark --master local[*]
```

Dans PySpark :
```python
df = spark.read.parquet("hdfs://namenode:9000/data/analytics/traffic/kpi_congestion")
df.show()
```

**R√©sultat attendu** :
```
+------------------+-----+
|congestion_status |count|
+------------------+-----+
|Mod√©r√©            |580  |
|Fluide            |320  |
|Dense             |85   |
|Bloqu√©            |15   |
+------------------+-----+
```

---

## üõ†Ô∏è Probl√®mes R√©solus

| Probl√®me                                                         | Cause                                                                       | Solution                                                         |
| ---------------------------------------------------------------- | --------------------------------------------------------------------------- | ---------------------------------------------------------------- |
| **Permission denied HDFS**                                       | Le r√©pertoire `/data/raw/traffic` appartenait √† `root`.                     | Utiliser `/user/hdfs/traffic` (propri√©taire : `hdfs`).           |
| **`socket.gaierror` DataNode**                                   | Le consumer Windows ne r√©solvait pas le hostname du DataNode Docker.        | Ex√©cuter le consumer **dans Docker** (service `consumer`).       |
| **`Connection refused localhost:9093`**                          | Kafka annon√ßait `localhost:9093` au lieu de `kafka:9093`.                   | Corriger `KAFKA_ADVERTISED_LISTENERS` dans `docker-compose.yml`. |
| **Consumer lit `localhost` malgr√© `KAFKA_BOOTSTRAP=kafka:9093`** | Le consumer Kafka √©tait cr√©√© au niveau module (avant lecture des env vars). | D√©placer la cr√©ation du consumer **dans `main()`**.              |

---

## üìã Fichiers Cl√©s Modifi√©s

### `docker-compose.yml`
- **Kafka** : `KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://kafka:9093`
- **Service `consumer`** : conteneur Python qui ex√©cute `kafka_to_hdfs.py` automatiquement au d√©marrage

### `scripts/kafka_to_hdfs.py`
- Variables d'environnement lues correctement
- Consumer cr√©√© **dans `main()`** (pas au niveau module)
- Gestion d'erreurs robuste pour la cr√©ation de r√©pertoires HDFS

---

## üîß Commandes Utiles

```powershell
# Red√©marrer la stack compl√®te
docker compose down
docker compose up -d

# Voir les logs d'un service
docker logs -f consumer
docker logs -f kafka
docker logs -f namenode

# V√©rifier l'√©tat des services
docker compose ps

# Supprimer les donn√©es HDFS (pour repartir de z√©ro)
docker exec -it namenode hdfs dfs -rm -r -skipTrash /user/hdfs/traffic
docker exec -it namenode hdfs dfs -mkdir -p /user/hdfs/traffic
docker exec -it namenode hdfs dfs -chown -R hdfs:hdfs /user/hdfs/traffic

# Lister les topics Kafka
docker exec -it kafka kafka-topics --bootstrap-server localhost:9093 --list

# Consommer le topic manuellement
docker exec -it kafka kafka-console-consumer \
    --bootstrap-server localhost:9093 \
    --topic traffic-events \
    --from-beginning \
    --max-messages 5
```

---

## üéØ Prochaines √âtapes

### √âtape 5 ‚Äì Traitement Spark
- Lire les fichiers `.jsonl` depuis HDFS
- Calculer des KPIs :
  - D√©bit moyen par zone
  - Vitesse moyenne par heure
  - D√©tection de congestion (occupancy > 80%, speed < 20 km/h)
- √âcrire les r√©sultats dans une base SQL ou HDFS

### √âtape 6 ‚Äì Visualisation Grafana
- API Python (Flask/FastAPI) exposant les KPIs
- Dashboard Grafana affichant :
  - Trafic en temps r√©el par zone
  - Heatmap de congestion
  - Alertes (accidents, embouteillages)

### √âtape 7 ‚Äì Orchestration Airflow
- DAG quotidien : traitement batch Spark
- DAG de monitoring : v√©rification sant√© du pipeline

---

## üìå R√®gles de D√©veloppement

1. **Code** : clair, simple, directement utilisable
2. **D√©pendances** : uniquement la stack d√©finie (pas d'ajouts non valid√©s)
3. **S√©curit√©** : variables d'environnement (pas de secrets en dur)
4. **Exceptions** : gestion propre avec logs explicites
5. **Commentaires** : expliquer le "Pourquoi", pas le "Quoi"

---

## üéâ Validation √âtape 4

**Checklist** :
- [x] Stack Docker fonctionnelle
- [x] Producteur Kafka envoie des √©v√©nements
- [x] Consumer Docker consomme et √©crit dans HDFS
- [x] R√©pertoires HDFS cr√©√©s dynamiquement (`year/month/day/zone`)
- [x] Fichiers `.jsonl` pr√©sents et lisibles
- [x] Partitionnement optimis√© (un fichier par zone et par batch)

**Commande de validation finale** :
```powershell
docker exec -it namenode hdfs dfs -cat /user/hdfs/traffic/year=2026/month=01/day=11/zone=Centre-Ville/traffic_*.jsonl | head -n 5
```

Si vous voyez du JSON valide ‚Üí **√âtape 4 R√âUSSIE** ‚úÖ

---

## üéâ Validation √âtape 5

**Checklist** :
- [x] Job Spark soumis avec succ√®s
- [x] Donn√©es HDFS lues et nettoy√©es
- [x] UDF `congestion_level` appliqu√©e
- [x] 4 KPIs calcul√©s (road_type, zone, hourly, congestion)
- [x] Parquet partitionn√© sauvegard√© dans `/data/analytics/traffic`
- [x] CSV √©chantillon cr√©√© dans `/data/processed/traffic`

**Commandes de validation** :
```powershell
# V√©rifier KPIs Parquet
docker exec -it namenode hdfs dfs -ls /data/analytics/traffic/kpi_congestion

# Lire CSV √©chantillon
docker exec namenode hdfs dfs -cat /data/processed/traffic/part-00000-*.csv > results.csv
Get-Content results.csv -Head 20
```

Si vous voyez les fichiers Parquet ET le CSV avec `congestion_status` ‚Üí **√âtape 5 R√âUSSIE** ‚úÖ

---

## üéâ Validation √âtape 6

**Fichiers cr√©√©s** :
- `api/api_analytics.py` : API FastAPI compl√®te (330 lignes)
- `api/requirements.txt` : D√©pendances Python
- Service Docker `api` dans `docker-compose.yml`

**Checklist** :
- [x] API FastAPI d√©marr√©e dans Docker (port 8000)
- [x] 4 endpoints REST fonctionnels :
  - `/traffic/zones` : Volume par zone
  - `/traffic/congestion` : Top zones congestionn√©es
  - `/traffic/speed` : Vitesse par road_type
  - `/traffic/trends` : V√©hicules par heure
- [x] Cache 5 minutes impl√©ment√©
- [x] Lecture Parquet depuis HDFS avec gestion des partitions Spark
- [x] CORS activ√© pour Grafana

**Commandes de validation** :
```powershell
# V√©rifier l'API
Invoke-WebRequest -Uri "http://localhost:8000/" -UseBasicParsing | Select-Object -ExpandProperty Content

# Tester zones
Invoke-WebRequest -Uri "http://localhost:8000/traffic/zones" -UseBasicParsing | Select-Object -ExpandProperty Content

# Tester congestion
Invoke-WebRequest -Uri "http://localhost:8000/traffic/congestion" -UseBasicParsing | Select-Object -ExpandProperty Content
```

**R√©sultat attendu** : JSON avec donn√©es des zones (Centre-Ville, P√©riph√©rie, Quartier-R√©sidentiel, Zone-Industrielle)

Si tous les endpoints retournent du JSON valide ‚Üí **√âtape 6 R√âUSSIE** ‚úÖ

**Grafana** : Installer plugin `simpod-json-datasource`, configurer Data Source vers `http://host.docker.internal:8000`, cr√©er dashboards.

---

**Projet r√©alis√© par** : Mohamed BOULAA LAM  
**Contact** : [GitHub](https://github.com/MohamedBOULAALAM/SmartCity_Traffic_Pipeline)  
**Date** : Janvier 2026
