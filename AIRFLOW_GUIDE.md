# Guide Ã‰tape 7 : Orchestration Airflow

## ðŸŽ¯ Objectif

Automatiser l'exÃ©cution du pipeline Big Data de bout en bout avec Apache Airflow.

---

## ðŸ“¦ DAGs CrÃ©Ã©s

### 1ï¸âƒ£ DAG Principal : `traffic_pipeline`

**FrÃ©quence** : `@hourly` (toutes les heures)

| Task                        | Type           | Description                                |
| --------------------------- | -------------- | ------------------------------------------ |
| `check_kafka_health`      | BashOperator   | VÃ©rifie connectivitÃ© Kafka via `nc -z` |
| `trigger_data_generation` | PythonOperator | GÃ©nÃ¨re 100 Ã©vÃ©nements de trafic        |
| `spark_processing`        | BashOperator   | ExÃ©cute le job Spark (KPIs)               |
| `validate_output`         | PythonOperator | VÃ©rifie les Parquet dans HDFS             |
| `archive_raw_data`        | BashOperator   | Archive/nettoie les donnÃ©es brutes        |

**Flux d'exÃ©cution** :

```
check_kafka_health â†’ trigger_data_generation â†’ spark_processing â†’ validate_output â†’ archive_raw_data
```

### 2ï¸âƒ£ DAG Monitoring : `traffic_pipeline_monitor`

**FrÃ©quence** : `*/15 * * * *` (toutes les 15 minutes)

- VÃ©rifie la santÃ© de Kafka, HDFS, Spark et l'API

---

## ðŸš€ AccÃ¨s Ã  l'Interface Airflow

### URL

**http://localhost:8085**

### CrÃ©er l'utilisateur admin (premiÃ¨re fois)

Si vous ne pouvez pas vous connecter, crÃ©ez l'utilisateur :

```powershell
docker exec airflow-webserver airflow users create `
    --username admin `
    --firstname Admin `
    --lastname User `
    --role Admin `
    --email admin@example.com `
    --password admin
```

### Identifiants

- **Username** : `admin`
- **Password** : `admin`

---

## ðŸ”§ Commandes Utiles

### VÃ©rifier les DAGs

```powershell
# Lister tous les DAGs
docker exec -it airflow-webserver airflow dags list

# VÃ©rifier un DAG spÃ©cifique
docker exec -it airflow-webserver airflow dags show traffic_pipeline
```

### Tester un DAG (sans l'exÃ©cuter rÃ©ellement)

```powershell
docker exec -it airflow-webserver airflow dags test traffic_pipeline 2026-01-11
```

### Activer le DAG

```powershell
docker exec airflow-webserver airflow dags unpause traffic_pipeline
```

### DÃ©clencher manuellement

```powershell
docker exec -it airflow-webserver airflow dags trigger traffic_pipeline
```

### Voir l'Ã©tat des tÃ¢ches

```powershell
docker exec -it airflow-webserver airflow tasks list traffic_pipeline
```

### ExÃ©cuter une tÃ¢che spÃ©cifique

```powershell
docker exec -it airflow-webserver airflow tasks run traffic_pipeline check_kafka_health 2026-01-11
```

---

## âš™ï¸ Modifications du DAG

### Simplification des dÃ©pendances Python

Le DAG a Ã©tÃ© simplifiÃ© pour **ne pas nÃ©cessiter** l'installation de packages Python supplÃ©mentaires (`confluent_kafka`, `hdfs`) dans le conteneur Airflow.

**Changements** :

- `trigger_data_generation` : Simule la gÃ©nÃ©ration (le producteur Kafka tourne dÃ©jÃ  en continu)
- `validate_output` : Utilise `subprocess` avec `docker exec` au lieu du client HDFS Python

**Avantage** : Le DAG fonctionne immÃ©diatement sans configuration supplÃ©mentaire.

---

## ðŸ“Š Utilisation de l'Interface Web

### 1ï¸âƒ£ Activer le DAG

1. Ouvrir **http://localhost:8085**
2. Se connecter (admin/admin)
3. Dans la liste des DAGs, trouver `traffic_pipeline`
4. Cliquer sur le **toggle** Ã  gauche pour activer le DAG (passer de Off Ã  On)

### 2ï¸âƒ£ DÃ©clencher manuellement

1. Cliquer sur le DAG `traffic_pipeline`
2. Cliquer sur le bouton **â–¶ Trigger DAG** en haut Ã  droite
3. Confirmer

### 3ï¸âƒ£ Voir l'exÃ©cution

1. Cliquer sur le DAG
2. Onglet **Graph** : visualiser le flux des tÃ¢ches
3. Onglet **Grid** : voir l'historique des exÃ©cutions
4. Cliquer sur une tÃ¢che pour voir les logs

### 4ï¸âƒ£ Consulter les logs

1. Cliquer sur une tÃ¢che (carrÃ© colorÃ©)
2. Cliquer sur **Log**
3. Les logs s'affichent avec les messages INFO, WARNING, ERROR

---

## âš™ï¸ Configuration du DAG

### Fichier : `dags/traffic_pipeline_dag.py`

**ParamÃ¨tres principaux** :

```python
default_args = {
    'owner': 'smartcity-team',
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
    'email_on_failure': True,
    'email': ['alertes@smartcity.local'],
}

with DAG(
    dag_id='traffic_pipeline',
    schedule_interval='@hourly',
    start_date=datetime(2026, 1, 7),
    catchup=False,
    ...
)
```

### Modifier la frÃ©quence

| Schedule        | Description                      |
| --------------- | -------------------------------- |
| `@hourly`     | Toutes les heures                |
| `@daily`      | Tous les jours Ã  minuit         |
| `0 */6 * * *` | Toutes les 6 heures              |
| `0 8 * * *`   | Tous les jours Ã  8h             |
| `None`        | DÃ©clenchement manuel uniquement |

---

## ðŸ› ï¸ DÃ©pannage

| ProblÃ¨me                      | Solution                                                                     |
| ------------------------------ | ---------------------------------------------------------------------------- |
| **DAG non visible**      | VÃ©rifier les erreurs :`docker exec airflow-webserver airflow dags list`   |
| **Import Error**         | VÃ©rifier la syntaxe Python du fichier DAG                                   |
| **Task Ã©choue**         | Consulter les logs dans l'interface ou via `docker logs airflow-webserver` |
| **Kafka non accessible** | VÃ©rifier que Kafka est running :`docker compose ps kafka`                 |
| **Spark job Ã©choue**    | VÃ©rifier les logs Spark :`docker logs spark-master`                       |

### Voir les erreurs de parsing

```powershell
docker exec -it airflow-webserver airflow dags report
```

### Recharger les DAGs

```powershell
docker exec -it airflow-scheduler airflow dags reserialize
```

---

## ðŸ“ˆ Monitoring

### MÃ©triques disponibles

Dans l'interface Airflow :

- **Nombre d'exÃ©cutions** : succÃ¨s, Ã©checs, en cours
- **DurÃ©e moyenne** de chaque tÃ¢che
- **DerniÃ¨re exÃ©cution** rÃ©ussie

### Alertes email

ConfigurÃ© avec `email_on_failure=True` dans `default_args`.

Pour activer les emails, configurer SMTP dans `airflow.cfg` ou variables d'environnement :

```yaml
# Dans docker-compose.yml (service airflow-webserver)
environment:
  - AIRFLOW__SMTP__SMTP_HOST=smtp.gmail.com
  - AIRFLOW__SMTP__SMTP_PORT=587
  - AIRFLOW__SMTP__SMTP_USER=votre@email.com
  - AIRFLOW__SMTP__SMTP_PASSWORD=votre_password
```

---

## ðŸŽ‰ Validation Ã‰tape 7

### Checklist

- [X] DAG `traffic_pipeline` crÃ©Ã©
- [X] DAG `traffic_pipeline_monitor` crÃ©Ã©
- [X] 5 tÃ¢ches dÃ©finies avec dÃ©pendances
- [X] Configuration `@hourly` avec `catchup=False`
- [X] Email on failure configurÃ©
- [X] Documentation des tÃ¢ches (doc_md)
- [X] DAGs dÃ©tectÃ©s par Airflow

### Commandes de validation

```powershell
# VÃ©rifier que les DAGs sont chargÃ©s
docker exec -it airflow-webserver airflow dags list | Select-String "traffic"

# Tester le DAG (simulation)
docker exec -it airflow-webserver airflow dags test traffic_pipeline 2026-01-11
```

### RÃ©sultat attendu

Dans l'interface Airflow (http://localhost:8085) :

- âœ… DAG `traffic_pipeline` visible
- âœ… DAG `traffic_pipeline_monitor` visible
- âœ… Toggle pour activer/dÃ©sactiver
- âœ… Historique des exÃ©cutions

---

## ðŸŽ¯ Pipeline Complet

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Airflow   â”‚ â† Orchestration @hourly
â”‚    (DAG)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                          â”‚
â”‚  1. Check Kafka â†’ 2. Generate Data â†’ 3. Spark Job â†’     â”‚
â”‚                                                          â”‚
â”‚  4. Validate Output â†’ 5. Archive Raw Data               â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    HDFS     â”‚â”€â”€â”€>â”‚   FastAPI   â”‚â”€â”€â”€>â”‚   Grafana   â”‚
â”‚  (Parquet)  â”‚    â”‚    (API)    â”‚    â”‚ (Dashboard) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

**Si tout est OK** â†’ **Ã‰tape 7 RÃ‰USSIE** âœ…

**Pipeline SmartCity Traffic Analytics COMPLET !** ðŸŽ‰
